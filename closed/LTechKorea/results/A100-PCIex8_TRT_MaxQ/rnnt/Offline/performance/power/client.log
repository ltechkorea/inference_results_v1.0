client 2021-03-17 06:03:01,100 [WARNING] Removing old loadgen logs directory '/home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp'
client 2021-03-17 06:03:01,105 [INFO] Sending command to the server: 'mlcommons/power client v3'
client 2021-03-17 06:03:01,105 [INFO] Got response: 'mlcommons/power server v3'
client 2021-03-17 06:03:01,105 [INFO] Sending command to the server: 'stop'
client 2021-03-17 06:03:01,106 [INFO] Got response: 'OK'
client 2021-03-17 06:03:01,106 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2021-03-17 06:03:01,313 [INFO] NTP:offset = 0.001 s, delay = 0.202 s 
client 2021-03-17 06:03:01,313 [INFO] Sending command to the server: 'time'
client 2021-03-17 06:03:01,314 [INFO] Got response: '1615986181.4035134'
client 2021-03-17 06:03:01,314 [INFO] The time difference between the client and the server is within range -89.767 ms..-88.705 ms
client 2021-03-17 06:03:01,314 [INFO] Sending command to the server: 'new,,f8ff3a44-e699-4f1f-8a58-6a399e8c2601'
client 2021-03-17 06:03:01,316 [INFO] Got response: 'OK 2021-03-17_06-03-01,eb4f9419-f09e-4ee2-91cb-1657467ab796'
client 2021-03-17 06:03:01,316 [INFO] Session id is '2021-03-17_06-03-01'
client 2021-03-17 06:03:01,316 [INFO] Sources: {"sources": {"client.py": "d1e75cb4b26101220ebd242e584cf3ca5d8f1996", "lib/__init__.py": "da39a3ee5e6b4b0d3255bfef95601890afd80709", "lib/client.py": "d42bebf5b74cb6ff3997e2a6c68422afac111a28", "lib/common.py": "b0bad80d8fa328a7636027d4d66ff453f8dd7889", "lib/external/ntplib.py": "4da8f970656505a40483206ef2b5d3dd5e81711d", "lib/server.py": "2ed36471c7af565d6c8438b2134edad1d7ddf166", "lib/source_hashes.py": "4cedff274c661cb1504052018fd4f00dfbf624ef", "lib/summary.py": "0db15d783907aa92038281af4e465545c0648ddb", "lib/time_sync.py": "76051226ec89287839723352f4162aaa24e0546a", "server.py": "99e1310e3f76292aef1b8792ce6b8c82f1d44d8b", "tests/unit/test_server.py": "64f11775bfed35232a0e8bb9593c0ff992432c59", "tests/unit/test_source_hashes.py": "cb41a7261eaf7d94ba5c0aae9c523174f6204be3"}, "modules": {"__main__": "client.py", "lib.client": "lib/client.py", "lib.common": "lib/common.py", "lib.external.ntplib": "lib/external/ntplib.py", "lib.source_hashes": "lib/source_hashes.py", "lib.summary": "lib/summary.py", "lib.time_sync": "lib/time_sync.py"}}
client 2021-03-17 06:03:01,319 [INFO] Running workload in ranging mode
client 2021-03-17 06:03:01,319 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2021-03-17 06:03:01,522 [INFO] NTP:offset = 0.001 s, delay = 0.202 s 
client 2021-03-17 06:03:01,522 [INFO] Sending command to the server: 'time'
client 2021-03-17 06:03:01,523 [INFO] Got response: '1615986181.6066437'
client 2021-03-17 06:03:01,523 [INFO] The time difference between the client and the server is within range -83.943 ms..-82.708 ms
client 2021-03-17 06:03:01,524 [INFO] Sending command to the server: 'session,2021-03-17_06-03-01,start,ranging'
client 2021-03-17 06:03:41,206 [INFO] Got response: 'OK'
client 2021-03-17 06:03:41,206 [INFO] Running the workload 'LOG_DIR=/home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3 code/main.py --benchmarks=rnnt --scenarios=Offline --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/'
client 2021-03-17 06:15:27,925 [INFO] Sending command to the server: 'session,2021-03-17_06-03-01,stop,ranging'
client 2021-03-17 06:15:38,345 [INFO] Got response: 'OK'
client 2021-03-17 06:15:38,352 [INFO] Packing logs into zip and uploading to the server
client 2021-03-17 06:15:38,374 [INFO] Zip file size: 22.2 kB
client 2021-03-17 06:15:38,393 [INFO] Got response: 'OK'
client 2021-03-17 06:15:38,394 [INFO] Running workload in testing mode
client 2021-03-17 06:15:38,394 [INFO] Synchronizing with the server and with ib-01.dc4-in.nvidia.com...
client 2021-03-17 06:15:38,597 [INFO] NTP:offset = 0.000 s, delay = 0.201 s 
client 2021-03-17 06:15:38,598 [INFO] Sending command to the server: 'time'
client 2021-03-17 06:15:38,599 [INFO] Got response: '1615986938.6797104'
client 2021-03-17 06:15:38,599 [INFO] The time difference between the client and the server is within range -81.626 ms..-80.295 ms
client 2021-03-17 06:15:38,599 [INFO] Sending command to the server: 'session,2021-03-17_06-03-01,start,testing'
client 2021-03-17 06:16:00,293 [INFO] Got response: 'OK'
client 2021-03-17 06:16:00,293 [INFO] Running the workload 'LOG_DIR=/home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp python3 code/main.py --benchmarks=rnnt --scenarios=Offline --test_mode=PerformanceOnly --config_ver=maxq --action="run_harness" \\\n\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/*/*/*/mlperf_log_detail.txt /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/ \\\n\t\t&& cp -v /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/*/*/*/mlperf_log_summary.txt /home/scratch.mlperf_inf_ci/mlPerf/L1/A100_PCIex8_MaxQ-Computelab-A100-PCIEx8-MaxQ-L1-2-2021-03-17-03-56-44-UTC/mlperf-inference/closed/NVIDIA/build/power_logs_temp/'
client 2021-03-17 06:27:47,718 [INFO] Sending command to the server: 'session,2021-03-17_06-03-01,stop,testing'
client 2021-03-17 06:27:57,928 [INFO] Got response: 'OK'
client 2021-03-17 06:27:57,934 [INFO] Packing logs into zip and uploading to the server
client 2021-03-17 06:27:57,953 [INFO] Zip file size: 22.2 kB
client 2021-03-17 06:27:57,970 [INFO] Got response: 'OK'
client 2021-03-17 06:27:57,971 [INFO] Done runs
