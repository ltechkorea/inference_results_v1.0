{
    "A100-PCIex1": {
        "active_sms": 60,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 1215
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 1185,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 2450,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 64,
        "graphs_max_seqlen": 200,
        "server_num_issue_query_threads": 1,
        "server_target_qps": 2600,
        "soft_drop": 1.0,
        "use_small_tile_gemm_plugin": true
    },
    "A100-PCIex2": {
        "active_sms": 60,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 2430
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 2370,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 4390,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 64,
        "graphs_max_seqlen": 200,
        "server_num_issue_query_threads": 2,
        "server_target_qps": 5160,
        "soft_drop": 1.0,
        "use_small_tile_gemm_plugin": true
    },
    "A100-PCIex8": {
        "config_ver": {
            "high_accuracy": {
                "server_target_qps": 9600
            },
            "high_accuracy_triton": {
                "server_target_qps": 9500
            },
            "maxq": {
                "server_target_qps": 17500
            },
            "maxq_high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 7500
            },
            "maxq_high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 9480,
                "use_triton": true
            },
            "maxq_triton": {
                "server_target_qps": 17000,
                "use_triton": true
            }
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A100-SXM-80GB-MIG_1x1g.10gb": {
        "active_sms": 100,
        "config_ver": {
            "hetero": {},
            "hetero_high_accuracy": {
                "gpu_batch_size": 16,
                "gpu_copy_streams": 2,
                "gpu_inference_streams": 2,
                "precision": "fp16",
                "server_target_qps": 160
            },
            "high_accuracy": {
                "gpu_batch_size": 16,
                "gpu_copy_streams": 2,
                "gpu_inference_streams": 2,
                "precision": "fp16",
                "server_target_qps": 170
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 170,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 360,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 16,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 1,
        "graphs_max_seqlen": 200,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 380,
        "soft_drop": 0.99,
        "use_small_tile_gemm_plugin": true
    },
    "A100-SXM-80GB-MIG_28x1g.10gb": {
        "config_ver": {
            "triton": {
                "server_target_qps": 9900,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 50,
        "extends": [
            "A100-SXM-80GB-MIG_1x1g.10gb"
        ],
        "gpu_batch_size": 16,
        "server_target_qps": 10080
    },
    "A100-SXM-80GB-MIG_56x1g.10gb": {
        "config_ver": {
            "high_accuracy_triton": {
                "deque_timeout_usec": 2000,
                "gpu_batch_size": 8,
                "precision": "fp16",
                "server_target_qps": 9300,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 20500,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 1000,
        "extends": [
            "A100-SXM-80GB-MIG_1x1g.10gb"
        ],
        "gpu_batch_size": 12,
        "server_target_qps": 20160
    },
    "A100-SXM-80GBx1": {
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 24,
                "precision": "fp16",
                "server_target_qps": 1550
            },
            "high_accuracy_triton": {
                "gpu_batch_size": 24,
                "precision": "fp16",
                "server_target_qps": 1400,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 2800,
                "use_triton": true
            }
        },
        "extends": [
            "A100-SXM4-40GBx1"
        ],
        "gpu_batch_size": 48,
        "server_target_qps": 3200
    },
    "A100-SXM-80GBx4": {
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 4750
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 4650,
                "use_triton": true
            },
            "maxq": {
                "server_target_qps": 10200
            },
            "maxq_high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 4300
            },
            "maxq_high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 4500,
                "use_triton": true
            },
            "maxq_triton": {
                "server_target_qps": 8780,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 8780,
                "use_triton": true
            }
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 4
            }
        },
        "server_target_qps": 11100
    },
    "A100-SXM-80GBx8": {
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 24,
                "precision": "fp16",
                "server_target_qps": 13100
            },
            "maxq": {
                "server_target_qps": 21500
            },
            "maxq_high_accuracy": {
                "gpu_batch_size": 24,
                "precision": "fp16",
                "server_target_qps": 10000
            },
            "maxq_high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 11205,
                "use_triton": true
            },
            "maxq_triton": {
                "server_target_qps": 22455,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 23000
            }
        },
        "extends": [
            "A100-SXM4-40GBx8"
        ],
        "gpu_batch_size": 48,
        "server_target_qps": 25800
    },
    "A100-SXM4-40GBx1": {
        "active_sms": 60,
        "config_ver": {
            "high_accuracy": {
                "precision": "fp16",
                "server_target_qps": 1550
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 1400,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 2800,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 64,
        "graphs_max_seqlen": 200,
        "server_num_issue_query_threads": 1,
        "server_target_qps": 3100,
        "soft_drop": 0.99,
        "use_small_tile_gemm_plugin": true
    },
    "A100-SXM4-40GBx8": {
        "active_sms": 60,
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 11500
            },
            "high_accuracy_triton": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 11205,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 22455,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 96,
        "graphs_max_seqlen": 240,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 24750,
        "soft_drop": 0.99,
        "use_small_tile_gemm_plugin": true
    },
    "A10x1": {
        "active_sms": 100,
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 8,
                "precision": "fp16",
                "server_target_qps": 390
            },
            "high_accuracy_triton": {
                "gpu_batch_size": 8,
                "precision": "fp16",
                "server_target_qps": 360,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 800,
                "use_triton": true
            }
        },
        "enable_interleaved": false,
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 16,
        "graphs_max_seqlen": 240,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 900,
        "soft_drop": 0.993,
        "use_small_tile_gemm_plugin": true
    },
    "A10x8": {
        "config_ver": {
            "high_accuracy_triton": {
                "server_target_qps": 3200
            },
            "triton": {
                "max_queue_delay_usec": 9000,
                "server_target_qps": 7000
            }
        },
        "scales": {
            "A10x1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A30-MIG_1x1g.3gb": {
        "config_ver": {
            "hetero": {},
            "hetero_high_accuracy": {
                "gpu_batch_size": 6,
                "precision": "fp16",
                "server_target_qps": 260
            },
            "high_accuracy_triton": {
                "precision": "fp16",
                "server_target_qps": 120,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 260,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 50000,
        "enable_interleaved": false,
        "extends": [
            "A30x1"
        ],
        "gemm_plugin_fairshare_cache_size": 120,
        "gpu_batch_size": 10,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 1,
        "graphs_max_seqlen": 200,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 260,
        "soft_drop": 0.99,
        "start_from_device": false,
        "use_small_tile_gemm_plugin": true,
        "workspace_size": 805306368
    },
    "A30-MIG_32x1g.3gb": {
        "config_ver": {
            "high_accuracy_triton": {
                "gpu_batch_size": 6,
                "precision": "fp16",
                "server_target_qps": 4000,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 8300,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 1000,
        "extends": [
            "A30-MIG_1x1g.3gb"
        ],
        "gpu_batch_size": 10,
        "server_target_qps": 10000
    },
    "A30x1": {
        "config_ver": {
            "high_accuracy": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 650
            },
            "high_accuracy_triton": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 600,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 1400,
                "use_triton": true
            }
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 0.58
            }
        },
        "server_target_qps": 1500,
        "soft_drop": 0.993
    },
    "A30x8": {
        "config_ver": {
            "high_accuracy": {
                "server_target_qps": 5250
            },
            "high_accuracy_triton": {
                "server_target_qps": 5200
            },
            "maxq": {},
            "maxq_high_accuracy": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 2240
            },
            "maxq_high_accuracy_triton": {
                "gpu_batch_size": 64,
                "precision": "fp16",
                "server_target_qps": 2240,
                "use_triton": true
            },
            "maxq_triton": {
                "server_target_qps": 2592,
                "use_triton": true
            },
            "triton": {
                "max_queue_delay_usec": 1000,
                "server_target_qps": 11000
            }
        },
        "scales": {
            "A30x1": {
                "server_target_qps": 8.0
            }
        },
        "server_target_qps": 11500
    },
    "T4x1": {
        "active_sms": 100,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "graph_specs": "(128, 4, 256, 4), (192, 128, 512, 4), (256, 192, 1536, 8), (384, 256, 2048, 16)",
                "precision": "fp16",
                "server_num_issue_query_threads": 0,
                "server_target_qps": 160
            },
            "high_accuracy_triton": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "graph_specs": "(128, 4, 256, 4), (192, 128, 512, 4), (256, 192, 1536, 8), (384, 256, 2048, 16)",
                "precision": "fp16",
                "server_num_issue_query_threads": 0,
                "server_target_qps": 144,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 324,
                "use_triton": true
            }
        },
        "gpu_batch_size": 16,
        "graphs_max_seqlen": 240,
        "server_num_issue_query_threads": 0,
        "server_target_qps": 360,
        "soft_drop": 0.993
    },
    "T4x20": {
        "active_sms": 100,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 20,
                "server_target_qps": 3300,
                "soft_drop": 0.992
            },
            "high_accuracy_triton": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 20,
                "server_target_qps": 3300,
                "soft_drop": 0.992,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 5000,
                "use_triton": true
            }
        },
        "gpu_batch_size": 14,
        "graphs_max_seqlen": 260,
        "server_num_issue_query_threads": 40,
        "server_target_qps": 5000,
        "soft_drop": 0.995
    },
    "T4x8": {
        "active_sms": 100,
        "config_ver": {
            "high_accuracy": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1330
            },
            "high_accuracy_triton": {
                "active_sms": 100,
                "gpu_batch_size": 8,
                "gpu_inference_streams": 1,
                "precision": "fp16",
                "server_num_issue_query_threads": 8,
                "server_target_qps": 1330,
                "use_triton": true
            },
            "triton": {
                "server_target_qps": 2200,
                "use_triton": true
            }
        },
        "gpu_batch_size": 14,
        "graphs_max_seqlen": 260,
        "server_num_issue_query_threads": 16,
        "server_target_qps": 2200,
        "soft_drop": 0.992
    },
    "Triton_CPU_2S_6258Rx1": {
        "batch_size": 0,
        "config_ver": {
            "openvino": {
                "input_dtype": "fp32",
                "model_name": "bert_int8_openvino",
                "num_instances": 26,
                "ov_parameters": {
                    "CPU_THROUGHPUT_STREAMS": "14",
                    "SKIP_OV_DYNAMIC_BATCHSIZE": "YES"
                },
                "precision": "fp32",
                "start_from_device": false,
                "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy",
                "use_triton": true
            }
        },
        "server_target_qps": 1
    },
    "Triton_CPU_4S_8380Hx1": {
        "batch_size": 0,
        "config_ver": {
            "openvino": {
                "batch_size": 0,
                "input_dtype": "fp32",
                "model_name": "bert_int8_openvino",
                "num_instances": 8,
                "ov_parameters": {
                    "CPU_THREADS_NUM": "112",
                    "CPU_THROUGHPUT_STREAMS": "4",
                    "ENABLE_BATCH_PADDING": "NO",
                    "SKIP_OV_DYNAMIC_BATCHSIZE": "YES"
                },
                "precision": "fp32",
                "server_target_qps": 19.5,
                "start_from_device": false,
                "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy",
                "use_triton": true
            }
        },
        "server_target_qps": 1
    },
    "benchmark": "bert",
    "default": {
        "coalesced_tensor": true,
        "enable_interleaved": true,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 2,
        "input_dtype": "int32",
        "input_format": "linear",
        "precision": "int8",
        "tensor_path": "${PREPROCESSED_DATA_DIR}/squad_tokenized/input_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/segment_ids.npy,${PREPROCESSED_DATA_DIR}/squad_tokenized/input_mask.npy",
        "use_cuda_thread_per_device": false,
        "use_graphs": true
    },
    "scenario": "Server"
}