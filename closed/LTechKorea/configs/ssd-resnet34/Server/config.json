{
    "A100-PCIex1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 770,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 2,
        "server_target_qps": 770,
        "use_cuda_thread_per_device": true
    },
    "A100-PCIex2": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 1572.5,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 1600,
        "use_cuda_thread_per_device": true
    },
    "A100-PCIex8": {
        "config_ver": {
            "maxq": {
                "server_target_qps": 5700
            },
            "maxq_triton": {
                "instance_group_count": 4,
                "server_target_qps": 5600,
                "use_triton": true
            }
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A100-SXM-80GB-MIG_1x1g.10gb": {
        "config_ver": {
            "hetero": {},
            "triton": {
                "deque_timeout_usec": 1000,
                "gpu_batch_size": 4,
                "instance_group_count": 4,
                "server_target_qps": 105,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 20000,
        "gpu_batch_size": 2,
        "gpu_copy_streams": 2,
        "gpu_inference_streams": 2,
        "server_target_qps": 100,
        "start_from_device": true,
        "use_cuda_thread_per_device": false
    },
    "A100-SXM-80GB-MIG_28x1g.10gb": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 2600,
                "use_graphs": false,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 2000,
        "extends": [
            "A100-SXM-80GB-MIG_1x1g.10gb"
        ],
        "gpu_batch_size": 2,
        "server_target_qps": 3000
    },
    "A100-SXM-80GB-MIG_56x1g.10gb": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 5800,
                "use_graphs": false,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 1000,
        "extends": [
            "A100-SXM-80GB-MIG_1x1g.10gb"
        ],
        "gpu_batch_size": 2,
        "server_target_qps": 7000
    },
    "A100-SXM-80GBx1": {
        "extends": [
            "A100-SXM4-40GBx1"
        ]
    },
    "A100-SXM-80GBx4": {
        "config_ver": {
            "maxq": {
                "server_target_qps": 3080
            },
            "maxq_triton": {
                "instance_group_count": 4,
                "server_target_qps": 3144,
                "use_triton": true
            },
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 3144,
                "use_triton": true
            }
        },
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 4
            }
        },
        "server_target_qps": 3250
    },
    "A100-SXM-80GBx8": {
        "config_ver": {
            "maxq": {
                "server_target_qps": 6300
            },
            "maxq_triton": {
                "instance_group_count": 4,
                "server_target_qps": 7100,
                "start_from_device": false,
                "use_triton": true
            }
        },
        "extends": [
            "A100-SXM4-40GBx8"
        ],
        "server_target_qps": 7650
    },
    "A100-SXM4-40GBx1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 910,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 925,
        "start_from_device": true,
        "use_cuda_thread_per_device": true
    },
    "A100-SXM4-40GBx8": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 7100,
                "start_from_device": false,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 7550,
        "start_from_device": true,
        "use_cuda_thread_per_device": true
    },
    "A10x1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 230,
                "start_from_device": false,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 8,
        "gpu_inference_streams": 4,
        "server_target_qps": 250,
        "start_from_device": false,
        "use_cuda_thread_per_device": true
    },
    "A10x8": {
        "config_ver": {
            "triton": {
                "gpu_inference_streams": 2,
                "max_queue_delay_usec": 500,
                "server_target_qps": 2000,
                "use_triton": true
            }
        },
        "scales": {
            "A10x1": {
                "server_target_qps": 8.0
            }
        }
    },
    "A30-MIG_1x1g.3gb": {
        "config_ver": {
            "hetero": {},
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 80,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 50000,
        "extends": [
            "A30x1"
        ],
        "gpu_batch_size": 2,
        "gpu_copy_streams": 1,
        "gpu_inference_streams": 1,
        "server_target_qps": 80,
        "start_from_device": false,
        "use_cuda_thread_per_device": false,
        "use_graphs": false,
        "workspace_size": 1610612736
    },
    "A30-MIG_32x1g.3gb": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 3000,
                "use_graphs": false,
                "use_triton": true
            }
        },
        "extends": [
            "A30-MIG_1x1g.3gb"
        ],
        "gpu_batch_size": 2,
        "server_target_qps": 3000
    },
    "A30x1": {
        "scales": {
            "A100-PCIex1": {
                "server_target_qps": 0.58
            }
        }
    },
    "A30x8": {
        "config_ver": {
            "maxq": {},
            "maxq_triton": {
                "instance_group_count": 4,
                "server_target_qps": 2736,
                "use_triton": true
            },
            "triton": {
                "max_queue_delay_usec": 500
            }
        },
        "scales": {
            "A100-PCIex8": {
                "server_target_qps": 0.58
            }
        }
    },
    "T4x1": {
        "config_ver": {
            "triton": {
                "instance_group_count": 4,
                "server_target_qps": 110,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 2000,
        "gpu_batch_size": 2,
        "gpu_inference_streams": 4,
        "server_target_qps": 110,
        "use_cuda_thread_per_device": false
    },
    "T4x20": {
        "config_ver": {
            "triton": {
                "gpu_batch_size": 2,
                "instance_group_count": 2,
                "server_target_qps": 2280,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 4,
        "gpu_inference_streams": 2,
        "server_target_qps": 2400,
        "use_cuda_thread_per_device": true
    },
    "T4x8": {
        "config_ver": {
            "triton": {
                "instance_group_count": 2,
                "server_target_qps": 720,
                "use_triton": true
            }
        },
        "deque_timeout_usec": 30000,
        "gpu_batch_size": 4,
        "gpu_inference_streams": 1,
        "server_target_qps": 1000,
        "use_cuda_thread_per_device": true
    },
    "Triton_CPU_2S_6258Rx1": {
        "config_ver": {
            "openvino": {
                "batch_size": 1,
                "input_dtype": "fp32",
                "map_path": "data_maps/coco/val_map.txt",
                "model_name": "ssd-resnet34_int8_openvino",
                "num_instances": 4,
                "ov_parameters": {
                    "CPU_THREADS_NUM": "56",
                    "CPU_THROUGHPUT_STREAMS": "2",
                    "ENABLE_BATCH_PADDING": "NO",
                    "SKIP_OV_DYNAMIC_BATCHSIZE": "YES"
                },
                "server_target_qps": 15.5,
                "start_from_device": false,
                "tensor_path": "${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/fp32",
                "use_triton": true
            }
        }
    },
    "Triton_CPU_4S_8380Hx1": {
        "config_ver": {
            "openvino": {
                "batch_size": 1,
                "input_dtype": "fp32",
                "map_path": "data_maps/coco/val_map.txt",
                "model_name": "ssd-resnet34_int8_openvino",
                "num_instances": 8,
                "ov_parameters": {
                    "CPU_THREADS_NUM": "112",
                    "CPU_THROUGHPUT_STREAMS": "4",
                    "ENABLE_BATCH_PADDING": "NO",
                    "SKIP_OV_DYNAMIC_BATCHSIZE": "YES"
                },
                "request_timeout_usec": 64000,
                "server_target_qps": 68.5,
                "start_from_device": false,
                "tensor_path": "${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/fp32",
                "use_triton": true
            }
        }
    },
    "benchmark": "ssd-resnet34",
    "default": {
        "active_sms": 100,
        "gpu_copy_streams": 4,
        "input_dtype": "int8",
        "input_format": "linear",
        "map_path": "data_maps/coco/val_map.txt",
        "precision": "int8",
        "tensor_path": "${PREPROCESSED_DATA_DIR}/coco/val2017/SSDResNet34/int8_linear",
        "use_deque_limit": true,
        "use_graphs": false
    },
    "scenario": "Server"
}
